{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary', 'deferral_payments', 'total_payments',\n",
    "                 'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses',\n",
    "                 'exercised_stock_options', 'other', 'long_term_incentive',\n",
    "                 'restricted_stock', 'director_fees'] \n",
    "\n",
    "# You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only 146 datapoints**\n",
    "\n",
    "'LOCKHART EUGENE E' has all features zero \n",
    "\n",
    "\n",
    "there are lots of NaNs! (considering only monetary features)\n",
    "    * only one parson has 1 one feature missing\n",
    "    * 11 have only 2 features\n",
    "    \n",
    "18 is POI and 128 is NOT\n",
    "\n",
    "## Explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "18\n",
      "no\n",
      "128\n",
      "{'salary': 26704229, 'to_messages': 'NaN', 'deferral_payments': 32083396, 'total_payments': 309886585, 'exercised_stock_options': 311764000, 'bonus': 97343619, 'restricted_stock': 130322299, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -7576788, 'total_stock_value': 434509511, 'expenses': 5235198, 'loan_advances': 83925000, 'from_messages': 'NaN', 'other': 42667589, 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 1398517, 'deferred_income': -27992891, 'long_term_incentive': 48521928, 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bonus': 0,\n",
       " 'deferral_payments': 0,\n",
       " 'deferred_income': 0,\n",
       " 'director_fees': 0,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 0,\n",
       " 'expenses': 0,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 0,\n",
       " 'long_term_incentive': 0,\n",
       " 'other': 0,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 0,\n",
       " 'restricted_stock_deferred': 0,\n",
       " 'salary': 0,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 0,\n",
       " 'total_stock_value': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "count_y = 0\n",
    "count_n = 0\n",
    "\n",
    "name_to_index = {}\n",
    "\n",
    "for idx, person in enumerate(data_dict.keys()):\n",
    "    name_to_index[person] = idx\n",
    "    \n",
    "    allzero = True\n",
    "    \n",
    "    if data_dict[person]['poi'] == 'NaN':\n",
    "        print person  \n",
    "    elif data_dict[person]['poi']:\n",
    "        count_y +=1\n",
    "    else:\n",
    "        count_n +=1\n",
    "        \n",
    "    for val in ['salary', 'deferral_payments', 'total_payments',\n",
    "                 'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses',\n",
    "                 'exercised_stock_options', 'other', 'long_term_incentive',\n",
    "                 'restricted_stock', 'director_fees']:\n",
    "        \n",
    "#         if data_dict[person][val] == 'NaN' or data_dict[person][val] >0:\n",
    "#             allzero = False\n",
    "#             break\n",
    "\n",
    "        if data_dict[person][val] == 'NaN':\n",
    "            #print person\n",
    "            #print str(val) +\" NaN\"\n",
    "            data_dict[person][val] = 0\n",
    "\n",
    "#         if data_dict[person][val] < 0:\n",
    "#             print person\n",
    "#             print str(val) +\" \"+str(data_dict[person][val])\n",
    "#             data_dict[person][val] = -1\n",
    "  \n",
    "#     if allzero == True:\n",
    "#         print person\n",
    "print \"yes\"\n",
    "print count_y\n",
    "\n",
    "print \"no\"\n",
    "print count_n\n",
    "\n",
    "print data_dict['TOTAL']\n",
    "data_dict['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "{'salary': 26704229, 'to_messages': 'NaN', 'deferral_payments': 32083396, 'total_payments': 309886585, 'exercised_stock_options': 311764000, 'bonus': 97343619, 'restricted_stock': 130322299, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -7576788, 'total_stock_value': 434509511, 'expenses': 5235198, 'loan_advances': 83925000, 'from_messages': 'NaN', 'other': 42667589, 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 1398517, 'deferred_income': -27992891, 'long_term_incentive': 48521928, 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n",
      "146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print name_to_index['TOTAL']\n",
    "\n",
    "print data_dict['TOTAL']\n",
    "\n",
    "print len(data_dict)\n",
    "data_dict['LOCKHART EUGENE E']\n",
    "\n",
    "backup_dict = data_dict\n",
    "\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 15)\n",
      "[128  51 107  21 142  64 128  97  20  51  44  53  80  36 129]\n",
      "[ 0  0  1  0  0  0 16 49  1  0  0  0  0  1  0]\n",
      "[ 18  95  38 125   4  82   2   0 125  95 102  93  66 109  17]\n",
      "32083396\n",
      "32083396.0\n"
     ]
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "#del data_dict[\"\"]\n",
    "#del data_dict[]\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = False,\n",
    "                    remove_all_zeroes=False, remove_any_zeroes=False)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "## investigate a bit\n",
    "print data.shape\n",
    "\n",
    "cols_z = (data == 0).sum(0)\n",
    "print cols_z #np.sort(rows_z)\n",
    "\n",
    "cols_n = (data < -1).sum(0)\n",
    "print cols_n #np.sort(rows_z)\n",
    "\n",
    "cols_p = (data >0).sum(0)\n",
    "print cols_p\n",
    "\n",
    "index = name_to_index['TOTAL']\n",
    "\n",
    "print data_dict['TOTAL'][features_list[2]]\n",
    "print data[index,2]\n",
    "\n",
    "#print rows\n",
    "#rows_n = (data < 0).sum(1)\n",
    "#print rows_n #np.sort(rows_n)\n",
    "\n",
    "\n",
    "# cols_v = (data > 0).sum(0)\n",
    "# print cols_v\n",
    "# #print rows_v #np.sort(rows_v)\n",
    "\n",
    "# print (cols_z + cols_v)\n",
    "\n",
    "#cols = (data == 0).sum(0)\n",
    "#print cols\n",
    "\n",
    "#print np.sort(cols)\n",
    "#print np.where(cols == 142)\n",
    "\n",
    "\n",
    "\n",
    "#print [20,  21,  36,  44,  51,  51,  53]\n",
    "\n",
    "#print [features_list[i] for i in [8,3,13,10,1,9,11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  3  3  3  3  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9 10 10 10 10\n",
      " 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 15]\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "rows_n = (data == 0).sum(1)\n",
    "print np.sort(rows_n)\n",
    "print np.median(rows_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "**financial features:** ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees']\n",
    "\n",
    "(all units are in US dollars)\n",
    "\n",
    "**email features:** ['to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi'] \n",
    "\n",
    "(units are generally number of emails messages; notable exception is ‘email_address’, which is a text string)\n",
    "\n",
    "**POI label:** [‘poi’] (boolean, represented as integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.79540\tPrecision: 0.23421\tRecall: 0.23550\tF1: 0.23485\tF2: 0.23524\n",
      "\tTotal predictions: 15000\tTrue positives:  471\tFalse positives: 1540\tFalse negatives: 1529\tTrue negatives: 11460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ./tester.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
